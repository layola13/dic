```json
{
  "word": "tokenizers",
  "phonetics": "/ˈtoʊkənaɪzərz/",
  "part_of_speech": "noun",
  "translation": "分词器",
  "definition": "Tools or algorithms used to break text into smaller units, or tokens, that can be processed for natural language processing tasks.",
  "example": "Tokenizers are essential for preparing data for machine learning models.",
  "synonyms": ["text parsers", "segmentation tools"],
  "antonyms": [],
  "usage": {
    "simple_present": [
      { "statement": "Tokenizers simplify text preprocessing.", "translation": "分词器简化了文本预处理。" },
      { "statement": "Most models require tokenizers for input.", "translation": "大多数模型需要分词器作为输入。" }
    ],
    "present_continuous": [
      { "statement": "Researchers are developing new tokenizers.", "translation": "研究人员正在开发新的分词器。" },
      { "statement": "The team is testing various tokenizers.", "translation": "团队正在测试各种分词器。" }
    ],
    "present_perfect": [
      { "statement": "They have implemented custom tokenizers.", "translation": "他们已经实现了自定义分词器。" },
      { "statement": "Many NLP tasks have utilized advanced tokenizers.", "translation": "许多自然语言处理任务已经利用了高级分词器。" }
    ],
    "simple_past": [
      { "statement": "They developed a tokenizer last year.", "translation": "他们去年开发了一种分词器。" },
      { "statement": "The project used standard tokenizers.", "translation": "该项目使用了标准分词器。" }
    ],
    "future_simple": [
      { "statement": "We will need tokenizers for the next phase.", "translation": "我们将需要分词器用于下一个阶段。" },
      { "statement": "The application will use multiple tokenizers.", "translation": "该应用将使用多个分词器。" }
    ]
  },
  "phrases": {
    "examples": [
      { "phrase": "use a tokenizer", "translation": "使用分词器" },
      { "phrase": "tokenizer performance", "translation": "分词器性能" }
    ],
    "idioms": [
      { "phrase": "tokenize text", "translation": "分词处理文本" },
      { "phrase": "advanced tokenization", "translation": "高级分词处理" }
    ]
  }
}
``` 