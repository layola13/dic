```json
{
  "word": "presupervised",
  "phonetics": "N/A",
  "part_of_speech": "adjective",
  "translation": "预监督的",
  "definition": "Referring to a machine learning approach where a model is initially trained on a large, unlabeled dataset using a self-supervised method before being fine-tuned on a smaller, labeled dataset. It combines self-supervised learning and supervised learning.",
  "example": "The presupervised model achieved higher accuracy compared to the model trained only with supervised learning.",
  "synonyms": [
    "self-supervised pre-trained",
    "semi-supervised",
    "weakly supervised"
  ],
  "antonyms": [
    "unsupervised",
    "purely supervised"
  ],
  "usage": {
    "general_context": [
      {
        "sentence": "Presupervised learning can leverage large amounts of unlabeled data to improve model performance.",
        "translation": "预监督学习可以利用大量的无标签数据来提高模型性能。"
      },
      {
        "sentence": "The presupervised approach is particularly useful when labeled data is scarce and expensive to obtain.",
        "translation": "当标签数据稀缺且获取成本高昂时，预监督方法特别有用。"
      }
    ],
    "computer_vision": [
      {
        "sentence": "In computer vision, presupervised models are often used for feature extraction before object detection.",
        "translation": "在计算机视觉中，预监督模型通常用于在对象检测之前进行特征提取。"
      },
      {
        "sentence": "A presupervised convolutional neural network can learn useful representations from images without explicit labels.",
        "translation": "一个预监督的卷积神经网络可以从图像中学习有用的表示，而不需要显式标签。"
      }
    ],
    "natural_language_processing": [
      {
        "sentence": "In NLP, presupervised learning is used to pre-train language models on vast amounts of text data.",
        "translation": "在自然语言处理中，预监督学习用于在大量文本数据上预训练语言模型。"
      },
      {
        "sentence": "Presupervised language models can then be fine-tuned for specific tasks like sentiment analysis or text classification.",
        "translation": "然后，可以对预监督语言模型进行微调，以用于特定任务，如情感分析或文本分类。"
      }
    ],
    "time_series_analysis": [
      {
        "sentence": "For time series data, presupervised models can learn temporal patterns from unlabeled sequences.",
        "translation": "对于时间序列数据，预监督模型可以从无标签序列中学习时间模式。"
      },
      {
        "sentence": "Presupervised training helps in capturing underlying dynamics before forecasting future values.",
        "translation": "预监督训练有助于在预测未来值之前捕捉潜在的动态。"
      }
    ],
    "speech_recognition": [
      {
        "sentence": "In speech recognition, presupervised models are used to learn acoustic features from unlabeled speech data.",
        "translation": "在语音识别中，预监督模型用于从无标签语音数据中学习声学特征。"
      },
      {
        "sentence": "Presupervised acoustic models can be adapted to different accents or languages with limited labeled data.",
        "translation": "预监督声学模型可以通过有限的标签数据适应不同的口音或语言。"
      }
    ]
  },
  "phrases": {
    "examples": [
      {
        "phrase": "presupervised learning",
        "translation": "预监督学习"
      },
      {
        "phrase": "presupervised pre-training",
        "translation": "预监督预训练"
      }
    ],
    "related_terms": [
      {
        "term": "self-supervised learning",
        "translation": "自监督学习"
      },
      {
        "term": "transfer learning",
        "translation": "迁移学习"
      },
      {
        "term": "fine-tuning",
        "translation": "微调"
      }
    ]
  }
}
``` 