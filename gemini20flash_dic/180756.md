```json
{
  "word": "regularization",
  "phonetics": "/ˌreɡjələraɪˈzeɪʃən/",
  "part_of_speech": "noun",
  "translation": "正则化",
  "definition": "In machine learning and statistics, regularization is the process of adding information in order to solve an ill-posed problem or to prevent overfitting. It is typically used to improve the generalization performance of a model on unseen data.",
  "example": "Regularization techniques are crucial for building robust machine learning models.",
  "synonyms": [
    "normalization",
    "standardization",
    "adjustment",
    "modification"
  ],
  "antonyms": [],
  "usage": {
    "general": [
      {
        "example": "The model uses L1 regularization to prevent overfitting.",
        "translation": "该模型使用 L1 正则化来防止过拟合。"
      },
      {
        "example": "Regularization helps in reducing the complexity of the model.",
        "translation": "正则化有助于降低模型的复杂性。"
      },
      {
        "example": "Different regularization techniques have different effects on the model's performance.",
        "translation": "不同的正则化技术对模型的性能有不同的影响。"
      }
    ],
    "L1_regularization": [
      {
        "example": "L1 regularization, also known as Lasso, adds the sum of the absolute values of the coefficients to the loss function.",
        "translation": "L1 正则化，也称为 Lasso，将系数的绝对值之和添加到损失函数中。"
      },
      {
        "example": "L1 regularization can lead to sparse models where some coefficients are exactly zero.",
        "translation": "L1 正则化可以产生稀疏模型，其中一些系数正好为零。"
      }
    ],
    "L2_regularization": [
      {
        "example": "L2 regularization, also known as Ridge regression, adds the sum of the squares of the coefficients to the loss function.",
        "translation": "L2 正则化，也称为岭回归，将系数的平方和添加到损失函数中。"
      },
      {
        "example": "L2 regularization shrinks the coefficients towards zero but does not typically set them exactly to zero.",
        "translation": "L2 正则化将系数缩小到接近零，但通常不会将它们精确地设置为零。"
      }
    ],
    "elastic_net_regularization": [
      {
        "example": "Elastic Net regularization is a combination of L1 and L2 regularization.",
        "translation": "弹性网络正则化是 L1 和 L2 正则化的组合。"
      },
      {
        "example": "Elastic Net can handle situations where there are many correlated predictors.",
        "translation": "弹性网络可以处理存在许多相关预测变量的情况。"
      }
    ],
    "dropout_regularization": [
      {
        "example": "Dropout is a regularization technique commonly used in neural networks.",
        "translation": "Dropout 是一种常用于神经网络的正则化技术。"
      },
      {
        "example": "Dropout randomly drops out some neurons during training to prevent overfitting.",
        "translation": "Dropout 在训练期间随机删除一些神经元以防止过拟合。"
      }
    ],
    "early_stopping": [
      {
        "example": "Early stopping is a regularization technique where training is stopped when the performance on a validation set starts to degrade.",
        "translation": "早停是一种正则化技术，当验证集的性能开始下降时，训练就会停止。"
      },
      {
        "example": "Early stopping prevents the model from overfitting by stopping training at the optimal point.",
        "translation": "早停通过在最佳点停止训练来防止模型过拟合。"
      }
    ]
  },
  "phrases": {
    "examples": [
      {
        "phrase": "regularization parameter",
        "translation": "正则化参数"
      },
      {
        "phrase": "regularization term",
        "translation": "正则化项"
      }
    ],
    "idioms": []
  }
}
``` 