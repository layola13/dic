entropy:/ˈɛntrəpi/ | n. | 熵；混乱；无序 | Entropy is a measure of disorder or randomness in a system.  It is a fundamental concept in thermodynamics and information theory.  High entropy indicates a high degree of disorder, while low entropy indicates a high degree of order. | Example: The entropy of a gas increases as it expands.  气体膨胀时，其熵增加。 The entropy of the universe is always increasing.  宇宙的熵总是在增加。 |近义词：disorder, randomness, chaos | 反义词：order, organization


USAGE->

一般现在时:
The entropy of the system is high. = 系统的熵很高。
Entropy measures the disorder of a system. = 熵测量系统的无序度。


一般过去时:
The entropy decreased after the system cooled. = 系统冷却后熵降低了。
The experiment showed a high level of entropy. = 实验显示了高水平的熵。


现在完成时:
The system has reached a state of maximum entropy. = 系统已经达到了最大熵的状态。
Scientists have studied entropy for many years. = 科学家们已经研究熵多年了。


过去完成时:
The entropy had already increased significantly before the intervention. = 干预之前熵已经显著增加了。
They had calculated the entropy before the reaction began. = 反应开始前他们已经计算了熵。


将来时:
The entropy will increase as the temperature rises. = 温度升高时，熵将增加。
We will measure the entropy of the mixture tomorrow. = 我们明天将测量混合物的熵。


虚拟语气:
If the entropy were lower, the system would be more ordered. = 如果熵更低，系统将更有序。
I wish the entropy of this room were lower. = 我希望这个房间的熵更低。


被动语态:
The entropy was calculated using a complex formula. = 熵是用一个复杂的公式计算出来的。
The entropy is being measured by the instrument. = 熵正在由仪器测量。


疑问句:
What is the entropy of this black hole? = 这个黑洞的熵是多少？
How is entropy calculated in this case? = 在这种情况下熵是如何计算的？


否定句:
The entropy is not constant in this process. = 在这个过程中熵不是恒定的。
The system did not show a significant increase in entropy. = 系统没有显示出熵的显著增加。


PHRASE->

maximum entropy: 最大熵
entropy increase: 熵增加
Boltzmann entropy: 波尔兹曼熵
Gibbs entropy: 吉布斯熵
Shannon entropy: 香农熵


词源:

The word "entropy" comes from the Greek word "εντροπία" (entropia), which means "a turning inward".  This term was coined by the German physicist Rudolf Clausius in the 19th century, based on his studies of thermodynamics.  Clausius chose this term because he viewed entropy as a measure of the "transformation content" of a system, reflecting the extent to which energy is unavailable for useful work.  The modern understanding of entropy, however, extends beyond thermodynamics to encompass information theory and other fields.
